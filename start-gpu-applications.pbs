#! /bin/bash
#PBS -N HADOOP
#PBS -l select=6:ncpus=16:mem=62gb:ngpus=1:gpu_model=m2075,walltime=72:00:00
#PBS -l place=scatter
#PBS -m abe
#PBS -j oe

# print command info to the log file
set -x

#PBS -l select=5:ncpus=1:ngpus=1:gpu_model=k20:mem=62gb,walltime=70:00:00
# copy output files from temporary directory to project directory when the job job terminates abnormally
#trap "cd $PBS_O_WORKDIR;mkdir $PBS_JOBID;cp -R $TMPDIR/* $PBS_JOBID" TERM

source /etc/profile.d/modules.sh  
module purge 
module add gcc/4.8.1 cuda-toolkit/5.5.22

# set running time
hours=55
minutes=00
seconds=00

# set the resource info
CORES=16
MEMORY=62
SLAVE_NODES=6
HBASE=False

. ${HADOOP_PBS_ECOSYSTEM_HOME}/bin/set-applications-env.sh
. ${HADOOP_PBS_ECOSYSTEM_HOME}/bin/hadoop-set-env.sh

${HADOOP_PBS_ECOSYSTEM_HOME}/bin/hadoop-pbs-configure.sh -c $CORES -m $MEMORY -s $SLAVE_NODES -k $HBASE

sleep 15

$HADOOP_HOME/bin/hadoop --config $HADOOP_CONF_DIR namenode -format
$HADOOP_HOME/sbin/hadoop-daemon.sh --config $HADOOP_CONF_DIR --script hdfs start namenode
$HADOOP_HOME/sbin/hadoop-daemon.sh --config $HADOOP_CONF_DIR --script hdfs start datanode
$HADOOP_HOME/sbin/yarn-daemon.sh --config $HADOOP_CONF_DIR start resourcemanager
$HADOOP_HOME/sbin/yarn-daemon.sh --config $HADOOP_CONF_DIR start nodemanager
$HADOOP_HOME/sbin/mr-jobhistory-daemon.sh start historyserver --config $HADOOP_CONF_DIR

$HADOOP_HOME/bin/hadoop fs -mkdir -p /user/$USER

time=$(($hours*3600+$minutes*60+$seconds))
sleep $time

$HADOOP_HOME/sbin/hadoop-daemon.sh --config $HADOOP_CONF_DIR --script hdfs stop namenode
$HADOOP_HOME/sbin/hadoop-daemon.sh --config $HADOOP_CONF_DIR --script hdfs stop datanode
$HADOOP_HOME/sbin/yarn-daemon.sh --config $HADOOP_CONF_DIR stop resourcemanager
$HADOOP_HOME/sbin/yarn-daemon.sh --config $HADOOP_CONF_DIR stop nodemanager
$HADOOP_HOME/sbin/mr-jobhistory-daemon.sh stop historyserver --config $HADOOP_CONF_DIR
${HADOOP_PBS_ECOSYSTEM_HOME}/bin/hadoop-pbs-cleanup.sh
